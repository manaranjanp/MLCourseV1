{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Overfitting and Underfitting a Model\n",
    "\n",
    "**Author:** Manaranjan Pradhan</br>\n",
    "**Email ID:** manaranjan@gmail.com</br>\n",
    "**LinkedIn:** https://www.linkedin.com/in/manaranjanpradhan/</br>\n",
    "**Website:** www.manaranjanp.com\n",
    "\n",
    "\n",
    "## 1. HR - Attrition Analytics\n",
    "\n",
    "Human Resources are critical resources of any organiazation. Organizations spend huge amount of time and money to hire and nuture their employees. It is a huge loss for companies if employees leave, especially the key resources. So if HR can predict weather employees are at risk for leaving the company, it will allow them to identify the attrition risks and help understand and provie necessary support to retain those employees or do preventive hiring to minimize the impact to the orgranization.\n",
    "\n",
    "## 2. Data Set\n",
    "\n",
    "This dataset is taken from kaggle https://www.kaggle.com/datasets/jacksonchou/hr-data-for-analytics\n",
    "\n",
    "\n",
    "### 2.1 Dependent variable\n",
    "\n",
    "Left : 0 if employee did not leave , 1 if left company\n",
    "\n",
    "### 2.2 Independent variables\n",
    "\n",
    "- **satisfaction_level** : means how much employee satisfied (0 less satisfied , 1 most satisfied)\n",
    "- **last_evaluation** : means employees' evaluation for last month (0 bad , 1 Excellent)\n",
    "- **number_project** : number of projects the employee worked on\n",
    "- **average_montly_hours** : average months employee spends at work per month\n",
    "- **time_spend_company** : years the employee spent in a company\n",
    "- **Work_accident** : 0 if he did not have an accident , 1 if had at least one\n",
    "- **promotion_last_5years** : 0 if he did not have any promotion in last 5 years , 1 if had at least one\n",
    "- **dept** : department in which employee works\n",
    "- **salary** : High, medium or low bracket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "sn.set_palette(\"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_df = pd.read_csv('HR_comma_sep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_encoded_df = pd.get_dummies(hr_df, columns=['dept', 'salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_encoded_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building a Decision Tree\n",
    "\n",
    "\n",
    "### 5.1. Setting X and y Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = list(hr_encoded_df.columns)\n",
    "X_features.remove('left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hr_encoded_df[X_features]\n",
    "y = hr_encoded_df.left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Split Dataset into train and test\n",
    "\n",
    "- Train: 80%\n",
    "- Test: 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, \\\n",
    "y_train, y_test = train_test_split( X,\n",
    "                                    y,\n",
    "                                    test_size = 0.2,\n",
    "                                    random_state = 23 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Build Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=1, criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Measuring Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5. Predict on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_probs = tree.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train, y_train_pred_probs[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6. Predicting on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_probs = tree.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_test_pred_probs[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Checking Underfitting and Overfitting\n",
    "\n",
    "### Underfitting:\n",
    "\n",
    "Underfitting occurs when a machine learning model is too simple or lacks the capacity to capture the underlying patterns in the data. It fails to learn the relevant relationships between the features and the target variable, resulting in poor performance on both the training and test data.\n",
    "\n",
    "\n",
    "### Overfitting: \n",
    "\n",
    "Overfitting: An overfit model tends to have high accuracy on the training data since it has effectively memorized the training examples. However, when evaluated on the test data, its performance drops significantly due to its inability to generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = []\n",
    "test_accuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Max Depth Vs Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in range(1, 20):\n",
    "    print(f\"Building a model with depth: {depth}\")\n",
    "    tree_model = DecisionTreeClassifier(max_depth = depth, criterion = 'gini')\n",
    "    tree_model.fit(X_train, y_train)\n",
    "    train_probs = tree_model.predict_proba(X_train)\n",
    "    train_accuracy.append(roc_auc_score(y_train, train_probs[:,1]))\n",
    "    test_probs = tree_model.predict_proba(X_test)    \n",
    "    test_accuracy.append(roc_auc_score(y_test, test_probs[:,1]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame({\"depth\" : list(range(1, 20)),\n",
    "                       \"train_accuracy\": train_accuracy,\n",
    "                       \"test_accuracy\": test_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Test Accuracy Vs Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.lineplot(data = acc_df,\n",
    "            x = 'depth',\n",
    "            y = 'train_accuracy',\n",
    "            label = 'train accuracy')\n",
    "sn.lineplot(data = acc_df,\n",
    "            x = 'depth',\n",
    "            y = 'test_accuracy',\n",
    "            label = 'test accuracy')\n",
    "plt.xlabel('Depth of the Decision Trees')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Finding Optimal Complexity: Max Depth\n",
    "\n",
    "### 7.1 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': list(range(1, 20)),\n",
    "          'criterion': ['gini', 'entropy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_grid = GridSearchCV(DecisionTreeClassifier(),\n",
    "                           param_grid = params,\n",
    "                           cv = 10,\n",
    "                           scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Checking Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results = pd.DataFrame(tuning_grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_results[grid_results.rank_test_score < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results[['param_criterion',\n",
    "              'param_max_depth',\n",
    "              'mean_test_score',\n",
    "              'std_test_score',\n",
    "              'rank_test_score']].sort_values('rank_test_score', ascending = True)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Finding Best Params and Best Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex1: Participant Exercise:\n",
    "\n",
    "- Build a KNN Classifier for the HR Attrition Problem using below 5 most important features.\n",
    "    - satisfaction_level,last_evaluation,number_project,average_montly_hours,time_spend_company\n",
    "- n_neighhour (number of neighbors) is a hyperparameter for KNN Classfier \n",
    "- n_neighhour is a factor of complexity in KNN model\n",
    "- Build models with n_neighbours varying from 2 to 20\n",
    "- Measure train and test accuracy against n_neighbours\n",
    "- Find the optimal value of n_neighbors using Grid Search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
